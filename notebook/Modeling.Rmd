---
title: "Modeling"
author: "Karine Almeida"
date: "2023-10-12"
output: html_document
---

#Modeling

- In this notebook we will apply machine learning models, with the aim of predicting the price of used cars based on the relationship between the price and a set of resources.  
- Since we are dealing with a continuous variable, we will apply regression, which is part of supervised machine learning models.  
- We will apply 4 models and, through evaluation metrics, identify the one that performs best. This model will be used to obtain the price prediction from the *(cars_test)* dataset.  


## Viewing the database   
```{r echo=TRUE, warning=FALSE}
cars_train <- read_csv("../data/cars_train_clean1.csv", show_col_types = FALSE)
glimpse(cars_train)
``` 
Detect near zero covariates  
```{r}
nearZeroVar(cars_train, saveMetrics = T)
```

Removing variables near zero covariates and variables with excess categories (high computational power)  
```{r}
cars_train <- subset(cars_train, 
                     select = -c(num_portas, blindado, cidade_vendedor, modelo, versao))

```

Dataset separation  
```{r}
set.seed(123)
separation <- sample(c("train", "test"),
                     size = nrow(cars_train),
                     replace = TRUE,
                     prob = c(0.8, 0.2))
```

Generating training and testing base
```{r}
train <- cars_train[separation == "train",]
nrow(train)
test <- cars_train[separation == "test",]
nrow(test)
```


Transforming variables into factors
```{r}
cars_train[,c("marca", "cor", "cambio", "tipo", "ano_de_fabricacao",
              "ano_modelo","veiculo_único_dono",
              "ipva_pago", "veiculo_licenciado",
              "tipo_vendedor","estado_vendedor", 
              "anunciante")]= 
  lapply(cars_train[,c("marca", "cor", "cambio", "tipo", "ano_de_fabricacao",
              "ano_modelo","veiculo_único_dono",
              "ipva_pago", "veiculo_licenciado",
              "tipo_vendedor","estado_vendedor", 
              "anunciante")], as.factor)

summary(cars_train)
```

Dummize qualitative variables before running the model 
```{r}
cars_train_dummy <- dummy_columns(.data = cars_train,
                             select_columns = 
                               c("marca","cor","cambio",
                                 "tipo","ano_de_fabricacao",
                                 "ano_modelo",
                                 "veiculo_único_dono",
                                 "ipva_pago", "veiculo_licenciado",
                                 "tipo_vendedor"
                                 ,"estado_vendedor","anunciante"),
                             remove_selected_columns = T,
                             remove_most_frequent_dummy = T)

summary(cars_train_dummy)
```

# Linear Models
Multiple Linear Regression
```{r}
modelo_cars_train <- lm(preco~., cars_train_dummy)
summary(modelo_cars_train)
```
  
Evaluating model
```{r}
predito_OLS <- predict(modelo_cars_train, cars_train_dummy)
metricas2(predito_OLS, cars_train_dummy$preco)
```
  
Multiple Nonlinear Regression (Box-Cox Transformation)
```{r}
lambda_BC <- powerTransform(cars_train_dummy$preco)
lambda_BC

#Inserindo o lambda de Box-Cox na base de dados para a estimação de um novo modelo
cars_train_dummy$bcpreco <- (((cars_train_dummy$preco ^ lambda_BC$lambda) - 1) / 
                                   lambda_BC$lambda)

#Estimando um novo modelo múltiplo com variável dependente transformada por Box-Cox 
modelo_cars_train_bc <- lm(formula = bcpreco ~ . -preco, na.rm = T,
                        data = cars_train_dummy)
summary(modelo_cars_train_bc)
```
    
Evaluating model  
```{r}
predito_bc <- predict(modelo_cars_train_bc, cars_train_dummy)
metricas2(predito_bc, cars_train_dummy$bcpreco)
```
  
# Tree regression  

Train tree
```{r}
tree <- rpart(preco ~ .,
                 data= train,
                 xval=5,
                 control = rpart.control(cp = 0, 
                                         minsplit = 2,
                                         maxdepth = 30))
```

Save the forecast train and test
```{r}
train_tree_predict <- predict(tree, train)
test_tree_predict <- predict(tree, test)
# investigate the forecast
train_tree_predict %>% tail
test_tree_predict %>% tail
```

creating residue variable for train and test
```{r}
train_tree_residue <- train$preco - train_tree_predict
test_tree_residue <- test$preco - test_tree_predict

#Investigate residue

train_tree_residue %>% tail
test_tree_residue %>%  tail
```

Evaluate the tree
```{r}
metricas2(train_tree_predict, train$preco)
metricas2(test_tree_predict, test$preco)
```
Graphical analysis
```{r}

#create a dataframe to plot the graph

#train
train_grap <- data.frame(
  predict = train_tree_predict,
  preco = train$preco,
  residue = train_tree_residue
)

scatterplot_color(train_grap, "predict", "preco", "residue")

#test
test_grap <- data.frame(
  predict = test_tree_predict,
  preco = test$preco,
  residue = test_tree_residue
)

scatterplot_color(test_grap, "predict", "preco", "residue")

```

Observe the complexity of tree paths (cp)
```{r}
tab_cp <- rpart::printcp(tree)
```

Here is a graphical visualization of CP vs error in cross validation
```{r}
rpart::plotcp(tree)
```
Identifying the best CP in cross-validation   
```{r}
tab_cp[which.min(tab_cp[,'xerror']),]
cp_min <- tab_cp[which.min(tab_cp[,'xerror']),'CP']
cp_min
```
Tuning tree  
```{r}
tree_tune <- rpart::rpart(preco ~ .,
                              data=train,
                              xval=0,
                              control = rpart.control(cp = cp_min, 
                                                      maxdepth = 30))
```

Predicted values of tree tune
```{r}
train_tree_tune_predict <- predict(tree_tune, train)
test_tree_tune_predict <- predict(tree_tune, test)

# investigate the forecast
train_tree_tune_predict %>% tail
test_tree_tune_predict %>% tail
```
creating residue variable for train and test of tree tune
```{r}
train_tree_tune_residue <- train$preco - train_tree_tune_predict
test_tree_tune_residue <- test$preco - test_tree_tune_predict
```

Evaluate the tuned tree
```{r}
metricas2(train_tree_tune_predict, train$preco)
metricas2(test_tree_tune_predict, test$preco)
```
Graphical analysis
```{r}

#create a dataframe to plot the graph

#train
train_tune_grap <- data.frame(
  predict = train_tree_tune_predict,
  preco = train$preco,
  residue = train_tree_tune_residue
)

scatterplot_color(train_tune_grap, "predict", "preco", "residue")

#test
test_tune_grap <- data.frame(
  predict = test_tree_tune_predict,
  preco = test$preco,
  residue = test_tree_tune_residue
)

scatterplot_color(test_tune_grap, "predict", "preco", "residue")

```

## Random Forest  

```{r}
set.seed(123)
rf <- randomForest::randomForest(
  preco ~ .,
  data = train,
  ntree = 500,
  importance = TRUE
)
```
  
Evaluating tree
```{r}
#creating variables with predicted values
pRF_train <- predict(rf, train)
pRF_test  <- predict(rf, test)

#creating variables from the residuals
rf_residue_train <- train$preco - pRF_train
rf_residue_test <- test$preco - pRF_test

#Evaluating the model
metricas2(pRF_train, train$preco)
metricas2(pRF_test, test$preco)
```

Graphical analysis
```{r}
#train
rf_train <- data.frame(
  predict = pRF_train,
  preco = train$preco,
  residue = rf_residue_train
)

scatterplot_color(rf_train, "predict", "preco", "residue")


#test
rf_test <- data.frame(
  predict = pRF_test,
  preco = test$preco,
  residue = rf_residue_test
)

scatterplot_color(rf_test, "predict", "preco", "residue")

```




**The selected model will be Random forest, as it presented the best RMSE and R2 evaluation metrics.** 
 